{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from scipy.stats.stats import pearsonr  \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import catboost\n",
    "from mlxtend.classifier import StackingCVClassifier,StackingClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_com=pd.read_csv(r\"F:\\data mining\\projects\\tianchi\\happiness\\happiness_test_complete.csv\",parse_dates=['survey_time'],encoding='latin-1')\n",
    "test_abbr=pd.read_csv(r\"F:\\data mining\\projects\\tianchi\\happiness\\happiness_test_abbr.csv\",parse_dates=['survey_time'], encoding='latin-1')\n",
    "train_com=pd.read_csv(r\"F:\\data mining\\projects\\tianchi\\happiness\\happiness_train_complete.csv\",parse_dates=['survey_time'])\n",
    "train_abbr=pd.read_csv(r\"F:\\data mining\\projects\\tianchi\\happiness\\happiness_train_abbr.csv\",parse_dates=['survey_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_com = train_com.loc[train_com['happiness'] != -8]\n",
    "y=train_com.pop('happiness')\n",
    "df_all=pd.concat((train_com,test_com),axis=0)\n",
    "\n",
    "# train_abbr = train_abbr.loc[train_abbr['happiness'] != -8]\n",
    "# y=train_abbr.pop('happiness')\n",
    "# df_all=pd.concat((train_abbr,test_abbr),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quantile_income1=train_abbr[(train_abbr.income>0)&(train_abbr.survey_type==1)].income.quantile(np.arange(0,1,0.1)).values\n",
    "quantile_income2=train_abbr[(train_abbr.income>0)&(train_abbr.survey_type==2)].income.quantile(np.arange(0,1,0.1)).values\n",
    "quantile_family_income1=train_abbr[(train_abbr.family_income>0)&(train_abbr.survey_type==1)].family_income.quantile(np.arange(0,1,0.1)).values\n",
    "quantile_family_income2=train_abbr[(train_abbr.family_income>0)&(train_abbr.survey_type==2)].family_income.quantile(np.arange(0,1,0.1)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_func(quantile,e):\n",
    "\n",
    "    if e>0 and e<=quantile[1]:\n",
    "        re=1\n",
    "    elif e>quantile[1] and e<=quantile[2]:\n",
    "        re= 2\n",
    "    elif e>quantile[2] and e<=quantile[3]:\n",
    "        re= 3\n",
    "    elif e>quantile[3] and e<=quantile[4]:\n",
    "        re= 4\n",
    "    elif e>quantile[4] and e<=quantile[5]:\n",
    "        re= 5\n",
    "    elif e>quantile[5] and e<=quantile[6]:\n",
    "        re= 6\n",
    "    elif e>quantile[6] and e<=quantile[7]:\n",
    "        re= 7\n",
    "    elif e>quantile[7] and e<=quantile[8]:\n",
    "        re= 8\n",
    "    elif e>quantile[8] and e<=quantile[9]:\n",
    "        re= 9\n",
    "    elif e>quantile[9]:\n",
    "        re= 10\n",
    "    else : #e<=0 , or e==nan\n",
    "        re=e\n",
    "    return re\n",
    "def level_income(x,quantile1,quantile2):\n",
    "    e=x[1]\n",
    "    if x[0]==1:\n",
    "        return quantile_func(quantile1,e)\n",
    "    else:\n",
    "        return quantile_func(quantile2,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def level_income(df,col):\n",
    "   \n",
    "#     x2=pd.qcut(df[(df[col]>0)&(df.survey_type==2)].income,10,labels=range(1,11))\n",
    "#     x1=pd.qcut(df[(df[col]>0)&(df.survey_type==1)].income,10,labels=range(1,11))\n",
    "#     x0=df[(df[col]<=0)][col].astype(np.int64)\n",
    "#     return pd.concat([x0,x1,x2])\n",
    "\n",
    "def log_income(e):\n",
    "\n",
    "    if e> 0:\n",
    "        return np.log10(e)//1\n",
    "    else:\n",
    "        return e\n",
    "def log_floor_area(e):\n",
    "    if e> 0:\n",
    "        return np.log(e)//1\n",
    "    else:\n",
    "        return e\n",
    "def level_BMI(e):\n",
    "    if e <15:\n",
    "        r = 0\n",
    "    elif e > 15 and e <= 16:\n",
    "        r=1\n",
    "    elif e >16 and e <= 18.5:\n",
    "        r=2\n",
    "    elif e > 18.5 and e <= 25:\n",
    "        r=3\n",
    "    elif e > 25 and e <= 30:\n",
    "        r=4\n",
    "    elif e > 30 and e <= 40:\n",
    "        r=5\n",
    "    else:\n",
    "        r = 6\n",
    "    return r\n",
    "def level_house(e):\n",
    "    if e<=4:\n",
    "        return e\n",
    "    elif e >= 5 and e <= 10:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "def level_work_yr(e):\n",
    "    if e<=1:\n",
    "        return e\n",
    "    elif e > 1 and e <= 5:\n",
    "        return 2\n",
    "    elif e > 5 and e <= 10:\n",
    "        return 3\n",
    "    elif e > 10 and e <= 20:\n",
    "        return 4\n",
    "    elif e > 20:\n",
    "        return 5\n",
    "    else:#nan\n",
    "        return -2 #dont know\n",
    "def level_family_m(e):\n",
    "    if e<=3:\n",
    "        return e\n",
    "    elif e > 3 and e <= 5:\n",
    "        return 4\n",
    "    elif e > 5 and e <= 10:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "def dfprocess(df):\n",
    "    df['BMI']=(df.weight_jin/2)/(df.height_cm/100)**2\n",
    "    df['BMI_level']=df['BMI'].apply(level_BMI)\n",
    "    df['BMI']=df['BMI']//1\n",
    "    df['age']=(2015-df['birth'])\n",
    "    df['age-level']=df['age']//10\n",
    "    df[\"house\"]=df['house'].apply(level_house)\n",
    "    df[\"family_m_level\"]=df['family_m'].apply(level_family_m)\n",
    "    df[\"work_yr_level\"]=df['work_yr'].apply(level_work_yr)\n",
    "#     df[\"family_income_log\"]=df['family_income'].apply(log_income)\n",
    "    df[\"floor_area_log\"]=df['floor_area'].apply(log_floor_area)\n",
    "    df[\"income_level\"]=df[['survey_type','income']].apply(lambda y: level_income(y,quantile_income1,quantile_income2 ),axis=1)\n",
    "    df[\"family_income_level\"]=df[['survey_type','family_income']].apply(lambda y: level_income(y,quantile_family_income1,quantile_family_income2 ),axis=1)\n",
    "\n",
    "    \n",
    "#     df = df.loc[df['happiness'] != -8]\n",
    "    df=df.drop(['id','survey_time','age'],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(*predict_test_y):\n",
    "    mean=np.mean(np.column_stack((predict_test_y)),axis=1)\n",
    "    return np.rint(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['family_income'].fillna(df_all['family_income'].mean(),inplace=True)\n",
    "df_all=dfprocess(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_income_diff(e):\n",
    "    if e<=4:\n",
    "        return e\n",
    "    elif e >= 5 and e <= 10:\n",
    "        return 5\n",
    "    elif e>10:\n",
    "        return 6\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def level_by10(e):\n",
    "    if e>0:\n",
    "        re=e//10 +1\n",
    "    elif e<=0:\n",
    "        re=e\n",
    "    else: #nan\n",
    "        re=0\n",
    "    return re\n",
    "def decade_level(e):\n",
    "    \n",
    "    if e>0 and e<2100:\n",
    "        e=2015-e\n",
    "        re=e//10+1\n",
    "\n",
    "    elif e<=0:\n",
    "        re=e\n",
    "    else: #nan, 9997\n",
    "        re=0\n",
    "    return re\n",
    "def dfProcessCom(df):\n",
    "    # difference between actual income and expectation\n",
    "    train_com['income_diff']=train_com.apply(lambda x: np.ceil((x['inc_exp']-x['income'])/x['income']) if ((x['inc_exp']>0) &(x['income']>0) )else np.nan, axis=1)\n",
    "    train_com['income_diff']=train_com['income_diff'].apply(level_income_diff)\n",
    "        \n",
    "    cols=['public_service_1','public_service_2','public_service_3','public_service_4','public_service_5','public_service_6','public_service_7','public_service_8','public_service_9',]\n",
    "    for col in cols:\n",
    "        df[col]=df[col].apply(level_by10)\n",
    "    df['marital_years']=df['marital_now'].apply(lambda x: np.log2(2015-x)//1 if x>0 else x)\n",
    "    df['inc_exp']=df['inc_exp'].apply(log_income)\n",
    "    df['s_income']=df['s_income'].apply(log_income)\n",
    "    cols=['m_birth','f_birth','marital_1st','edu_yr','join_party','marital_now','s_birth']\n",
    "    for col in cols:\n",
    "        df[col]=df[col].apply(decade_level)\n",
    "#     df['floor_area']=df['floor_area'].apply(np.log1p).round(1)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=dfProcessCom(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['work_type'].fillna(0,inplace=True)\n",
    "df_all['work_status'].fillna(0,inplace=True)\n",
    "df_all['work_manage'].fillna(0,inplace=True)\n",
    "df_all['work_yr'].fillna(0,inplace=True)\n",
    "df_all['minor_child'].fillna(0,inplace=True)\n",
    "df_all['marital_years'].fillna(0,inplace=True)\n",
    "df_all['edu_status'].fillna(0,inplace=True)\n",
    "df_all['hukou_loc'].fillna(4,inplace=True)\n",
    "df_all['social_neighbor'].fillna(-8,inplace=True)\n",
    "df_all['social_friend'].fillna(-8,inplace=True)\n",
    "df_all['family_income'].fillna(df_all['family_income'].mean(),inplace=True)\n",
    "df_all=df_all.drop(['edu_other', 'invest_other', 'property_other', 's_work_status', 's_work_type',    's_birth',\n",
    "                    's_work_exper', 's_income','s_hukou','s_political', 's_edu',\n",
    "                   'invest_0', 'invest_2', 'invest_3', 'invest_4', 'invest_5', 'invest_6','invest_7', 'invest_8'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.describe().T.iloc[:50]\n",
    "# df_all.describe().T.iloc[50:100]\n",
    "# df_all.describe().T.iloc[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_large=['birth', 'income', 'floor_area' ,'height_cm', 'weight_jin', 'family_income', 's_birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_all=df_all.columns.values\n",
    "cols_old=['birth','floor_area', 'height_cm', 'weight_jin', 'work_yr', 'income','family_income',]\n",
    "cols_new=['BMI', 'BMI_level', 'age-level', 'floor_area_log', 'income_level', 'family_income_level','work_yr_level','family_income_level'],\n",
    "cols_abbr=[ 'survey_type', 'province', 'city', 'county', 'gender',\n",
    "       'birth', 'nationality', 'religion', 'religion_freq', 'edu', 'income',\n",
    "       'political', 'floor_area', 'height_cm', 'weight_jin', 'health',\n",
    "       'health_problem', 'depression', 'hukou', 'socialize', 'relax', 'learn',\n",
    "       'equity', 'class', 'work_exper', 'work_status', 'work_yr', 'work_type',\n",
    "       'work_manage', 'family_income', 'family_m', 'family_status', 'house',\n",
    "       'car', 'marital', 'status_peer', 'status_3_before', 'view',\n",
    "       'inc_ability']\n",
    "float_cols=['birth', 'income',   'floor_area', 'height_cm', 'weight_jin', 'work_yr', 'family_income','BMI','family_m',]\n",
    "cat_cols_abbr=['survey_type', 'province', 'city', 'county', 'gender', 'nationality', 'religion', 'political',  'hukou','work_exper', 'work_status',\n",
    "       'work_type', 'work_manage',  'marital',]\n",
    "cat_cols_com=['survey_type', 'province', 'city', 'county', 'gender', 'nationality', 'religion','edu_status' ,'political',  'hukou','work_exper', 'work_status',\n",
    "       'work_type', 'work_manage',  'marital','hukou_loc','s_political','s_hukou','s_work_exper','s_work_status','f_political','f_work_14','m_birth','m_political','m_work_14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols=np.intersect1d(cols_all,cat_cols_com)\n",
    "df_dummies=pd.get_dummies(data=df_all, columns=dummy_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full=df_dummies.iloc[:len(y)];y_full=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testindex=np.loadtxt(r'testindex.txt')\n",
    "trainindex=np.loadtxt(r'trainindex.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = df_dummies.iloc[:len(y)].loc[trainindex],df_dummies.iloc[:len(y)].loc[testindex],\n",
    "\n",
    "y_train, y_test = y.loc[trainindex],y.loc[testindex],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submit=df_dummies.iloc[len(y):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols=df_dummies.columns\n",
    "cols_cat=np.intersect1d(cols,cat_cols_com).tolist()\n",
    "cols_cat_cat=np.setdiff1d(cols_cat,np.array(['work_status', 'work_yr', 'work_type', 'work_manage'])).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "483"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.513770655983976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45466843403949836"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_r1 = lgb.LGBMRegressor(boosting_type='gbdt', colsample_bytree=1,learning_rate=0.05,n_estimators=1000,max_depth=4)\n",
    "lgb_r1.fit(X_train[cols], y_train,eval_metric ='mean_squared_error')\n",
    "lgb_r1_y2 = lgb_r1.predict(X_test[cols],)\n",
    "mse=mean_squared_error(np.rint(lgb_r1_y2), y_test)\n",
    "print(mse)\n",
    "mean_squared_error(lgb_r1_y2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.514271407110666\n"
     ]
    }
   ],
   "source": [
    "xgb_r1 = xgb.XGBRegressor(max_depth=5)\n",
    "xgb_r1.fit(X_train[cols], y_train)\n",
    "xgb_r1_y3 = xgb_r1.predict(X_test[cols])\n",
    "mse=mean_squared_error(np.rint(xgb_r1_y3), y_test)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4543244510373861"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(xgb_r1_y3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5027541311967952\n"
     ]
    }
   ],
   "source": [
    "cat_r1 = catboost.CatBoostRegressor(depth=4)\n",
    "cat_r1.fit(X_train[cols], y_train,verbose=0)\n",
    "cat_r1_y1 = cat_r1.predict(X_test[cols])\n",
    "mse=mean_squared_error(np.rint(cat_r1_y1), y_test)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4543244510373861"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(xgb_r1_y3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.441173021688527"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean=np.stack((xgb_r1_y3,lgb_r1_y2,cat_r1_y1,cat_r1_y1)).mean(axis=0)\n",
    "mean_squared_error(mean, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x241b14b6ac8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_r1.fit(X_full[cols], y,eval_metric ='mean_squared_error')\n",
    "xgb_r1.fit(X_full[cols], y)\n",
    "cat_r1.fit(X_full[cols], y,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submit_y1 = cat_r1.predict(test_submit[cols])\n",
    "test_submit_y2 = lgb_r1.predict(test_submit[cols])\n",
    "test_submit_y3 =xgb_r1.predict(test_submit[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit=np.stack((test_submit_y3,test_submit_y2,test_submit_y1,test_submit_y1)).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sub_csv=pd.Series(submit,index=test_abbr.id,name=\"happiness\")\n",
    "sub_csv.to_csv('sub_csv_6.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2968, 41)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_abbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submit_y1 = cat_r1.predict(test_submit[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5873810716074112"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_c1 = xgb.XGBClassifier(subsample=0.8,)\n",
    "xgb_c1.fit(X_train[cols], y_train)\n",
    "xgb_c1_y3 = xgb_c1.predict(X_test[cols])\n",
    "mean_squared_error(np.rint(xgb_c1_y3), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5162744116174262"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_c1 = lgb.LGBMRegressor(boosting_type='gbdt', colsample_bytree=1,learning_rate=0.05,n_estimators=1000,max_depth=4)\n",
    "lgb_c1.fit(X_train[cols], y_train,eval_metric ='mean_squared_error')\n",
    "lgb_c1_y2 = lgb_c1.predict(X_test[cols],)\n",
    "mean_squared_error(np.rint(lgb_r1_y2), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, random_state=42,shuffle=True)\n",
    "parameters ={'max_depth':[2,3,4,5,6],'num_leaves':[10,20]}\n",
    "lgb_cv=lgb.LGBMRegressor()\n",
    "grid_xgb=GridSearchCV(estimator=lgb_cv,param_grid=parameters,cv=kf,scoring='neg_mean_squared_error')\n",
    "grid_xgb.fit(X_full,y_full)\n",
    "grid_xgb.best_params_\n",
    "#{'max_depth': 4, 'min_child_weight': 1}\n",
    "RMSE=np.sqrt(-grid_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 5}"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, random_state=42,shuffle=True)\n",
    "parameters ={'depth':[2,3,4,5,6],}\n",
    "cat_cv=catboost.CatBoostRegressor(verbose=0)\n",
    "grid_xgb=GridSearchCV(estimator=cat_cv,param_grid=parameters,cv=kf,scoring='neg_mean_squared_error')\n",
    "grid_xgb.fit(X_full,y_full)\n",
    "grid_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6772063693946946"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-grid_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
